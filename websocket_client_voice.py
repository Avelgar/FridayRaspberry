#!/home/avelgar/myenv/bin/python3
import asyncio
import websockets
import ssl
import json
import time
import logging
import base64
import threading
import queue
from vosk import Model, KaldiRecognizer
import os
from datetime import datetime
import cv2
import sys
import subprocess  # –ù—É–∂–Ω–æ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ RHVoice

# === –ë–õ–û–ö –î–õ–Ø –û–¢–ö–õ–Æ–ß–ï–ù–ò–Ø –®–£–ú–ê ALSA ===
from ctypes import *
from contextlib import contextmanager

try:
    ERROR_HANDLER_FUNC = CFUNCTYPE(None, c_char_p, c_int, c_char_p, c_int, c_char_p)
    def py_error_handler(filename, line, function, err, fmt):
        pass
    c_error_handler = ERROR_HANDLER_FUNC(py_error_handler)
except:
    pass

@contextmanager
def no_alsa_err():
    try:
        asound = cdll.LoadLibrary('libasound.so')
        asound.snd_lib_error_set_handler(c_error_handler)
        yield
        asound.snd_lib_error_set_handler(None)
    except:
        yield
# =====================================

sys.stdout.reconfigure(line_buffering=True)

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
URI = "wss://friday-assistant.ru/ws"
RECONNECT_DELAY = 5
PING_INTERVAL = 30

MODEL_PATH = "/home/avelgar/vosk-model-small-ru-0.22" 

BOT_NAME = "–ø—è—Ç–Ω–∏—Ü–∞"
VOICE_NAME = "anna" # –ì–æ–ª–æ—Å–∞: anna, aleksandr, elena, irina (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ç–æ–≥–æ, —á—Ç–æ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ)

commands_queue = queue.Queue()

try:
    import pyaudio
    PA_AVAILABLE = True
except ImportError:
    PA_AVAILABLE = False

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
speech_rec_instance = None

# --- –§–£–ù–ö–¶–ò–ò ---

def speak(text):
    """–°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏ —á–µ—Ä–µ–∑ RHVoice"""
    print(f"üó£Ô∏è –ì–û–í–û–†–Æ: {text}")
    
    # 1. –°—Ç–∞–≤–∏–º –º–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–∞ –ø–∞—É–∑—É, —á—Ç–æ–±—ã –Ω–µ —Å–ª—ã—à–∞—Ç—å —Å–∞–º–∏—Ö —Å–µ–±—è
    if speech_rec_instance:
        speech_rec_instance.pause_listening()
    
    try:
        # –ö–æ–º–∞–Ω–¥–∞: echo "—Ç–µ–∫—Å—Ç" | RHVoice-test -p –≥–æ–ª–æ—Å | play -t wav -
        # play - —ç—Ç–æ —É—Ç–∏–ª–∏—Ç–∞ –∏–∑ –ø–∞–∫–µ—Ç–∞ sox. –ú–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ aplay
        cmd = f'echo "{text}" | RHVoice-test -p {VOICE_NAME} -o - | aplay'
        subprocess.run(cmd, shell=True)
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏: {e}")
    
    # 2. –í–∫–ª—é—á–∞–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω –æ–±—Ä–∞—Ç–Ω–æ
    if speech_rec_instance:
        speech_rec_instance.resume_listening()


async def send_command(websocket, command, bot_name, mac):
    current_time = datetime.now().isoformat()
    command_message = {
        "command": command, "timestamp": current_time,
        "name": bot_name, "command_type": "–≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ", "mac": mac
    }
    json_msg = json.dumps(command_message, ensure_ascii=False)
    encoded = base64.b64encode(json_msg.encode('utf-8')).decode('utf-8')
    await websocket.send(encoded)
    print(f"üì§ –û–¢–ü–†–ê–í–õ–ï–ù–û: {command}")

def process_message(message_json):
    """–†–∞–∑–±–æ—Ä –æ—Ç–≤–µ—Ç–∞ –æ—Ç —Å–µ—Ä–≤–µ—Ä–∞"""
    try:
        data = json.loads(message_json)
        msg_type = data.get("type")

        if msg_type == "new_message":
            actions = data.get("actions", [])
            
            for action in actions:
                if "–≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç|" in action:
                    try:
                        _, text = action.split("|", 1)
                        print("\n" + "="*30)
                        print(f"üîä –ë–û–¢ –û–¢–í–ï–¢–ò–õ: {text}")
                        # –í–´–ó–´–í–ê–ï–ú –§–£–ù–ö–¶–ò–Æ –°–ò–ù–¢–ï–ó–ê –†–ï–ß–ò
                        speak(text)
                        print("="*30 + "\n")
                    except ValueError:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –¥–µ–π—Å—Ç–≤–∏—è: {action}")
                
                elif "–æ—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏" in action:
                     print("üßπ –ö–æ–º–∞–Ω–¥–∞ –æ—á–∏—Å—Ç–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏")

        elif msg_type == "ping":
            pass
            
        else:
            print(f"‚ÑπÔ∏è –°–æ–æ–±—â–µ–Ω–∏–µ —Ç–∏–ø–∞ {msg_type}: {data}")

    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ JSON: {e}")

# ===================================================================
# === –ö–õ–ê–°–° –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–Ø ===
# ===================================================================
class SpeechRecognizer:
    def __init__(self, commands_queue):
        self.model = None
        self.recognizer = None
        self.audio = None
        self.stream = None
        self.is_listening = False
        self.is_paused = False  # –§–ª–∞–≥ –ø–∞—É–∑—ã –¥–ª—è TTS
        self.commands_queue = commands_queue
        self.device_index = None
        self.sample_rate = 16000
        
        if not PA_AVAILABLE:
            print("‚ùå PyAudio –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
            return
        
        if os.path.exists(MODEL_PATH):
            try:
                self.model = Model(MODEL_PATH)
                print(f"‚úÖ Vosk –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {MODEL_PATH}")
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏: {e}")
        else:
            print(f"‚ùå –ù–µ—Ç –º–æ–¥–µ–ª–∏ –ø–æ –ø—É—Ç–∏: {MODEL_PATH}")

    def find_input_device(self):
        print("üîç –ü–æ–∏—Å–∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ Fifine...")
        with no_alsa_err():
            self.audio = pyaudio.PyAudio()
            
        count = self.audio.get_device_count()
        candidate = None
        
        # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ USB —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
        for i in range(count):
            try:
                info = self.audio.get_device_info_by_index(i)
                name = info.get('name', '').lower()
                inputs = info.get('maxInputChannels', 0)
                
                if inputs > 0:
                    if "fifine" in name:
                        candidate = i
                        print(f"   ‚≠êÔ∏è –ù–ê–®–ï–õ FIFINE [{i}]")
                        break
                    if "usb" in name and "ms2109" not in name and candidate is None:
                        candidate = i
            except:
                continue
        
        if candidate is None:
             # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –ø–æ–ø–∞–≤—à–∏–π—Å—è, –µ—Å–ª–∏ —Å–ø–µ—Ü. –º–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –Ω–∞–π–¥–µ–Ω
             for i in range(count):
                 if self.audio.get_device_info_by_index(i).get('maxInputChannels') > 0:
                     candidate = i
                     break

        if candidate is not None:
            self.device_index = candidate
            # –ü—Ä–æ–±—É–µ–º 16000 –¥–ª—è Vosk, —ç—Ç–æ –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ
            for rate in [16000, 44100, 48000]:
                try:
                    if self.audio.is_format_supported(rate, input_device=candidate, input_channels=1, input_format=pyaudio.paInt16):
                        self.sample_rate = rate
                        print(f"‚úÖ –ú–∏–∫—Ä–æ—Ñ–æ–Ω index {candidate}. –ß–∞—Å—Ç–æ—Ç–∞: {rate} Hz")
                        return True
                except: pass
            return True
            
        print("‚ùå –ú–∏–∫—Ä–æ—Ñ–æ–Ω—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        return False

    def pause_listening(self):
        """–ü—Ä–∏–æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø–æ—Ç–æ–∫, —á—Ç–æ–±—ã –æ—Å–≤–æ–±–æ–¥–∏—Ç—å –∞—É–¥–∏–æ –¥–ª—è –¥–∏–Ω–∞–º–∏–∫–∞"""
        if self.stream and self.stream.is_active():
            self.is_paused = True
            # –ú—ã –Ω–µ –∑–∞–∫—Ä—ã–≤–∞–µ–º –ø–æ—Ç–æ–∫ –ø–æ–ª–Ω–æ—Å—Ç—å—é, –ø—Ä–æ—Å—Ç–æ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–ª–∏ —Å—Ç–∞–≤–∏–º –Ω–∞ –ø–∞—É–∑—É
            # –ù–æ –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ—Å—Ç–∏ –Ω–∞ RPi –ª—É—á—à–µ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å stream
            try:
                self.stream.stop_stream()
                print("‚è∏Ô∏è –ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–∞ –ø–∞—É–∑–µ...")
            except: pass

    def resume_listening(self):
        """–í–æ–∑–æ–±–Ω–æ–≤–ª—è–µ—Ç –ø–æ—Ç–æ–∫"""
        if self.stream and self.stream.is_stopped():
            try:
                self.stream.start_stream()
                self.is_paused = False
                print("‚ñ∂Ô∏è –ú–∏–∫—Ä–æ—Ñ–æ–Ω –∞–∫—Ç–∏–≤–µ–Ω")
            except: pass

    def audio_callback(self, in_data, frame_count, time_info, status):
        if self.is_paused:
            return (None, pyaudio.paContinue)

        if self.recognizer and self.is_listening:
            if self.recognizer.AcceptWaveform(in_data):
                res = json.loads(self.recognizer.Result())
                text = res.get('text', '').strip()
                if text:
                    print(f"üé§ –°–õ–´–®–£: '{text}'")
                    if BOT_NAME in text.lower():
                        cmd = text.lower().replace(BOT_NAME, '').strip()
                        print(f"‚ö° –†–ê–°–ü–û–ó–ù–ê–ù–û: {cmd}")
                        self.commands_queue.put(cmd or "—Å–ª—É—à–∞—é")
        return (in_data, pyaudio.paContinue)
    
    def start_listening(self):
        if not self.model: return
        try:
            if not self.find_input_device(): return

            self.recognizer = KaldiRecognizer(self.model, self.sample_rate)
            
            self.stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.sample_rate,
                input=True,
                input_device_index=self.device_index,
                frames_per_buffer=4000, # –ù–µ–º–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–∏–ª –±—É—Ñ–µ—Ä –¥–ª—è RPi
                stream_callback=self.audio_callback
            )
            self.is_listening = True
            self.stream.start_stream()
            print("‚úÖ –ü–û–¢–û–ö –ê–£–î–ò–û –ó–ê–ü–£–©–ï–ù")
            while self.is_listening: time.sleep(1)    
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞: {e}")

# ===================================================================
# === –ö–ê–ú–ï–†–ê ===
# ===================================================================
class FastCameraDisplay:
    def __init__(self):
        self.camera = None
        self.is_running = True
        
    def start_display(self):
        # –û—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –±—ã–ª–æ, –Ω–æ –≤–∞–∂–Ω–æ: –∫–∞–º–µ—Ä–∞ –º–æ–∂–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤–∞—Ç—å –∑–∞ USB –ø—Ä–æ–ø—É—Å–∫–Ω—É—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å
        # –µ—Å–ª–∏ –∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω –∏ –∫–∞–º–µ—Ä–∞ –Ω–∞ –æ–¥–Ω–æ–º –∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä–µ USB 2.0
        print("üì∑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã...")
        for idx in [0, -1]: # –£–ø—Ä–æ—Å—Ç–∏–ª –ø–µ—Ä–µ–±–æ—Ä
            cap = cv2.VideoCapture(idx, cv2.CAP_V4L2)
            if cap.isOpened():
                cap.set(3, 320)
                cap.set(4, 240)
                if cap.read()[0]:
                    self.camera = cap
                    break
                cap.release()
        
        if not self.camera:
            return

        # –ï—Å–ª–∏ —Ä–∞–±–æ—Ç–∞–µ—à—å –±–µ–∑ –¥–∏—Å–ø–ª–µ—è (headless), —É–±–µ—Ä–∏ imshow
        try:
            # cv2.namedWindow("Robot", cv2.WND_PROP_FULLSCREEN)
            # cv2.setWindowProperty("Robot", cv2.WND_PROP_FULLSCREEN, 1)
            pass
        except: pass
        
        while self.is_running:
            ret, frame = self.camera.read()
            if ret:
                # cv2.imshow("Robot", frame) # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –µ—Å–ª–∏ –µ—Å—Ç—å —ç–∫—Ä–∞–Ω
                # if cv2.waitKey(1) == ord('q'): break
                time.sleep(0.05)
            else: break
        if self.camera: self.camera.release()
        cv2.destroyAllWindows()

# ===================================================================
# === WEBSOCKET ===
# ===================================================================
def get_mac_address():
    try:
        with open('/sys/class/net/wlan0/address', 'r') as f: return f.read().strip()
    except: return "unknown"

async def websocket_handler():
    mac = get_mac_address()
    ssl_ctx = ssl.create_default_context()
    # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–≤ –µ—Å–ª–∏ –æ–Ω–∏ —Å–∞–º–æ–ø–æ–¥–ø–∏—Å–∞–Ω–Ω—ã–µ
    ssl_ctx.check_hostname = False
    ssl_ctx.verify_mode = ssl.CERT_NONE 
    
    while True:
        try:
            print(f"üåê –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ {URI}...")
            async with websockets.connect(URI, ssl=ssl_ctx) as ws:
                print("‚úÖ WebSocket –ü–û–î–ö–õ–Æ–ß–ï–ù!")
                
                reg = json.dumps({"MAC": mac, "DeviceName": "PiBot", "Password": "123"})
                await ws.send(base64.b64encode(reg.encode()).decode())
                
                last_ping = time.time()
                
                while True:
                    if time.time() - last_ping > PING_INTERVAL:
                        ping = json.dumps({"type": "ping", "timestamp": time.time(), "mac": mac})
                        try:
                            await ws.send(base64.b64encode(ping.encode()).decode())
                            last_ping = time.time()
                        except: break
                    
                    while not commands_queue.empty():
                        cmd = commands_queue.get()
                        await send_command(ws, cmd, "–ü—è—Ç–Ω–∏—Ü–∞", mac)
                    
                    try:
                        msg = await asyncio.wait_for(ws.recv(), timeout=0.1)
                        decoded = base64.b64decode(msg).decode()
                        process_message(decoded)
                    except asyncio.TimeoutError:
                        pass
                    
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {e}. –†–µ–∫–æ–Ω–Ω–µ–∫—Ç {RECONNECT_DELAY}—Å...")
            await asyncio.sleep(RECONNECT_DELAY)

def main():
    global speech_rec_instance
    print("="*40)
    print("ü§ñ –°–ò–°–¢–ï–ú–ê –ó–ê–ü–£–°–ö–ê–ï–¢–°–Ø (RPI 3B+)...")
    print("="*40)
    
    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏
    speech_rec_instance = SpeechRecognizer(commands_queue)
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ
    t_voice = threading.Thread(target=speech_rec_instance.start_listening, daemon=True)
    t_voice.start()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º WebSocket
    t_ws = threading.Thread(target=lambda: asyncio.run(websocket_handler()), daemon=True)
    t_ws.start()
    
    time.sleep(2)
    # –ö–∞–º–µ—Ä—É –∑–∞–ø—É—Å–∫–∞–µ–º –≤ –≥–ª–∞–≤–Ω–æ–º –ø–æ—Ç–æ–∫–µ –∏–ª–∏ —Ç–æ–∂–µ –≤ —Ñ–æ–Ω–µ
    FastCameraDisplay().start_display()

if __name__ == "__main__":
    main()